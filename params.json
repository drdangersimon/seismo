{"name":"Seismo","tagline":"Place to keep my asteroseismology-related stuff","body":"seismo\r\n======\r\n\r\nPlace to keep my asteroseismology-related stuff\r\n\r\n## Note\r\n\r\nI just started this but the aim is to have a small set of tools that will allow\r\nme to extract frequencies from an unevenly sampled dataset e.g. Kepler\r\nlightcurve. This requires a LOT of processing power, which is why there are\r\nmultiple parallel implementations of the O(N^2) Deeming periodogram, including\r\none that runs on my GPU via `opencl`.\r\n\r\n\r\n## Modules\r\n\r\nseismo contains the following modules:\r\n\r\n* timeseries - contains some DFT implementations\r\n* fitting - will contain frequency fitting routines\r\n\r\n## Tests\r\nRun the tests with:\r\n\r\n    py.test tests\r\n\r\n\r\n## Goals\r\n\r\nKepler datasets can be very long and contain many datapoints. These take a long\r\ntime to calculate via a naive O(N^2) algorithm (but needed because I don't have\r\na better algorithm for unevenly sampled data that I'm happy with). For this\r\nreason I'm trying to create something that can run more or less with only some\r\nuser input, so that I can let it run by itself and save each step in the\r\noutput.\r\n\r\nEach DFT for the particular dataset I'm interested in takes about 50min to run\r\non my GTX 760, and about 16 hours on my MBP's i5 with 2 threads, and I may need to do 40 - 50 of them to extract all the\r\nfrequencies. (Donations for a Nvidia 980 welcome)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}